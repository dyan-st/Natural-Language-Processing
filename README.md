# Natural Language Processing with nltk in python

Do you want to understand long text files like transcripts and essays better?
Try this Python code which uses the Natural Language Toolkit!

This Python code runs through a txt or Excel file and outputs the top 25 most common words, enabling you to quantify qualitative data!

It:
1. Tokenizes essays and long text files into individual words
2. Removes stopwords like And, But, If, Then
3. Lemmatizes words by setting them to the same tense, eg driving, driven, drive
4. Produces a list with counts of the top 25 words
5. Produces a frequency distribution table which visualizes the data

Output example:
[("s'pore", 369), ('man', 268), ('tharman', 147), ('george', 131), ('goh', 131), ("m'sia", 123), ('election', 110), ('arrested', 101), ('allegedly', 99), ('police', 88), ('car', 86), ('ng', 84), ('kok', 84), ('song', 84), ('tan', 82), ('kin', 82), ('lian', 82), ('â€˜', 77), ('presidential', 77), ('open', 72)]
![image](https://github.com/dyan-st/nltk/assets/140136462/02c2c8ba-d2e7-466f-bb30-396f129a5b1e)


